# doc-rel

This tiny program demonstrates the use of word embedding model for locating related articles.

## installation & prerequisite

To run this program, you'll need to have Python 3 installed.

Install the dependencies:

```bash
# will install numpy, gensim, and jieba
pip3 install -r requirements.txt
```

### required input files

- `corpus.txt`, each sentence in a single line, plain text
- `articles.json`, a list of objects with at least these fields (title, body, id) representing the articles, each field is a string, the file is in json format

Those input files are no longer useful once the model is trained and the article database is generated.

## usage

### find articles related to a given article

```bash
$ python3 ssi.py sim 217699
3.84685636729   : 打破疆界的物联网和 AR 技术，如何让「虚拟」更加「现实」？
3.61724271244   : 专注操作系统技术，中科创达发布 TurboX「智能大脑」平台
3.59738345349   : 对于 PC、触屏手机之后计算平台的人机交互，Google 是怎么看的？
3.46270459857   : 微软、Google、IBM重金布局，量子计算与我们十年后的世界
3.43106296409   : 吴恩达：百度新开放的语音技术有潜力彻底改变人机交互
3.42430097898   : 当别人还在用人工智能构建未来，搜狗已经将 AI 融入了现在
3.40786358509   : 总融资过亿美元，他想让你过钢铁侠般的智控生活
3.40710506251   : 璇玑：智能投顾的非典型演化
3.38436826075   : 高德开放平台推出 LBS 游戏行业解决方案 提供专业地图平台能力支持
3.3501803571    : Google Daydream 在中国的第一次演讲，都说了啥？
```

In this example `217699` represents the querying article id. In my testing examples, it points to this this article: [打破疆界的物联网和 AR 技术，如何让「虚拟」更加「现实」？](http://www.geekpark.net/topics/217699).

### finding articles related to given keywords

```bash
$ python3 ssi.py kw '京东'
2.40102515298   : 京东全球智选助力美国融硅登陆中国
2.13992414627   : 乐视控股联合兴业银行跨界合作 体育会员可享金融服务
2.09966448199   : 京东、聚美、蘑菇街携手腾讯云，分享「双十一」电商风控安全心得
2.01190108608   : 苹果回应自动关机：大家别急，我们正和问题用户联系|2016年11月17日极客早知道
1.94554587584   : 蚂蚁金服与阿里云启动「蚂云计划」：服务全球 5 万家金融机构
1.93188359361   : 企途时代·2016 企业服务创投峰会成功举办，IT 桔子发布企业服务创投白皮书
1.92917382516   : YunOS 互联网汽车迎来 3 位「新成员」
1.9018890173    : 支付宝要把十个海外机场变商场
1.90078956102   : 京东接入今日头条，想让你在读文章时「不由自主」地一键下单
1.89655877182   : 又下一城，途家宣布并购携程、去哪儿的公寓民宿业务
```

In this example '京东' is the querying keyword. The keyword can be any sentence and will be segmentized using jieba.

### generated files

- `word2vec.model`: the word2vec model trained for the given corpus
- `article_db.bin`: the article database with each article associated with its pre-calculated bag-of-word representation

Once these files are generated, the input files can be deleted safely.

In order to re-generate the model, or to reload the articles, remove the corresponding generated files. These files will be computed and generated by need.

## techniques

- *word2vec* is used to find word embedding (Mikolov et al., '13)
- *Supervised Semantic Indexing*, or *SSI* is used to calculate document relevancy ranking (Bai et al, '09)

## license

GPLv3



