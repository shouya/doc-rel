# doc-rel

This tiny program demonstrates the use of word embedding model for locating related articles.

## installation & prerequisite

To run this program, you'll need to have Python 3 installed.

Install the dependencies:

```bash
# will install numpy, gensim, and jieba
pip3 install -r requirements.txt
```

### required input files

- `corpus.txt`, each sentence in a single line, plain text
- `articles.json`, a list of objects with at least these fields (title, body, id) representing the articles, each field is a string, the file is in json format

Those input files are no longer useful once the model is trained and the article database is generated.

## usage

### find articles related to a given article

```bash
$ python3 ssi.py sim 217699
2.13198899294   : 打破疆界的物联网和 AR 技术，如何让「虚拟」更加「现实」？
1.15135923978   : ThoughtWorks 发布新一期技术雷达，强调增强现实（AR）
0.847500265669  : 京东发起 VR/AR 产业推进联盟，更强调 AR 布局
0.825280328229  : 阿里巴巴 1500 万美元投资的 Infinity AR，可能成为 AR 设备普及的关键因素
0.761123266508  : 2017，虚拟越来越现实
0.621158115784  : 从巴黎车展的 VR/AR 元素说开去
0.570553338498  : Focalmax 发布 Scati ONE VR/AR一体机
0.533311997558  : 易瞳科技召开「VR/AR照进现实」行业应用研讨会
0.434134904495  : 想去硅谷发展，创业公司该如何选择加速器？
0.400667196302  : 在被阿里和京东称霸的「白条生意」里，这家创业公司如何拿到了 5 亿融资？
```

In this example `217699` represents the querying article id. In my testing examples, it points to this this article: [打破疆界的物联网和 AR 技术，如何让「虚拟」更加「现实」？](http://www.geekpark.net/topics/217699).

### finding articles related to given keywords

```bash
$ python3 ssi.py kw '京东'
1.50328955078   : 京东 CTO 张晨：京东要成为人工智能实践者和推动者
1.37310452498   : 你在京东上每下一单，背后都有这些他们没告诉你的事
1.03824354385   : 京东打造「语音购物」，「多快好省」的背后是怎样的技术变革？
1.02038319821   : 京东全球智选助力美国融硅登陆中国
0.878368431531  : 京东接入今日头条，想让你在读文章时「不由自主」地一键下单
0.84315728172   : 京东智能云语音服务开放平台上线「唤醒」全新语音交互未来
0.76815645032   : 为情怀充值，Nokia 6 京东预约超 15 万 | 极客早知道 2017 年 1 月 12 日
0.759598675191  : 在被阿里和京东称霸的「白条生意」里，这家创业公司如何拿到了 5 亿融资？
0.743158714877  : 京东、聚美、蘑菇街携手腾讯云，分享「双十一」电商风控安全心得
0.719228294327  : 13 岁的京东和 13 岁的亚马逊
```

In this example '京东' is the querying keyword. The keyword can be any sentence and will be segmentized using jieba.

### generated files

- `word2vec.model`: the word2vec model trained for the given corpus
- `article_db.bin`: the article database with each article associated with its pre-calculated bag-of-word representation

Once these files are generated, the input files can be deleted safely.

In order to re-generate the model, or to reload the articles, remove the corresponding generated files. These files will be computed and generated by need.

## techniques

- *TF-IDF* is used to assign each word a weight representing their significances
- *word2vec* is used to find word embedding (Mikolov et al., '13)
- *Supervised Semantic Indexing*, or *SSI* is used to calculate document relevancy ranking (Bai et al, '09)

## license

GPLv3


